{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import base64\n",
    "from io import StringIO\n",
    "import snowflake.connector as sf\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import pandas as pd\n",
    "load_dotenv()\n",
    "from e2b_code_interpreter import Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sf_client():\n",
    "    conn = sf.connect(\n",
    "    user=os.getenv('SF_USER'),\n",
    "    password=os.getenv('SF_PASSWORD'),\n",
    "    account=os.getenv('SF_ACCOUNT'),\n",
    "    warehouse=os.getenv('SF_WAREHOUSE'),\n",
    "    database=os.getenv('SF_DATABASE'),\n",
    "    schema=os.getenv('SF_SCHEMA'),\n",
    "    role='FRED_ROLE',\n",
    "    private_key_file = 'rsa_key.p8'\n",
    "    )\n",
    "    return conn\n",
    " \n",
    "conn = sf_client()\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cursor.execute('select * from STOCK_DATA').fetch_pandas_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('local', exist_ok=True)\n",
    "df.to_csv('local/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM SQL Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.snowflake.core import write_to_csv\n",
    "from utils.helper import sql_query_generation_prompt\n",
    "from utils.litellm.core import llm\n",
    "import json \n",
    "\n",
    "result = llm(model='gemini/gemini-1.5-pro', system_prompt=sql_query_generation_prompt, user_prompt='generate 5 sql queries', is_json=True)\n",
    "print(result)\n",
    "answer = json.loads(result['answer']) if isinstance(result['answer'], str) else result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('local/charts.json', 'w') as f:\n",
    "    f.write(json.dumps(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqls = []\n",
    "# for _ in answer:\n",
    "#     sqls.append(_['SQL']+';')\n",
    "# with open('local/charts.sql', 'w') as f:\n",
    "#     f.write(\"\\n\".join(sqls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL (Snowflake) -> CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.snowflake.core import write_to_csv\n",
    "\n",
    "# with open('local/charts.sql', 'r') as f:\n",
    "#     sql_content = f.read()\n",
    "    \n",
    "# for idx, sql in enumerate(sql_content.split('\\n')):\n",
    "#     write_to_csv(sql, idx )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('local/3.csv', parse_dates=['DATA_DATE'])\n",
    "df.head(5).to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e2b_code_interpreter import Sandbox\n",
    "import base64\n",
    "import json\n",
    "import pandas as pd\n",
    "from utils.litellm.core import llm\n",
    "from utils.helper import sql_query_generation_prompt, python_code_generation_prompt\n",
    "from utils.s3.core import upload_png_to_s3, get_s3_client\n",
    "from utils.snowflake.core import write_to_csv\n",
    "chart_data = []\n",
    "with open('local/charts.json', 'r') as f:\n",
    "    chart_metadata = json.loads(f.read())\n",
    "for idx, _ in enumerate(chart_metadata):\n",
    "    df = write_to_csv(_['SQL'].strip(';'))\n",
    "    sbx = Sandbox()\n",
    "    top_5_data = pd.read_csv('local/data.csv').head(5).to_string()\n",
    "    with open(\"local/data.csv\", \"rb\") as file:\n",
    "        sbx.files.write(\"/home/user/sandbox/data.csv\", file)\n",
    "    result = llm(model='gemini/gemini-2.5-pro-exp-03-25', system_prompt=python_code_generation_prompt, user_prompt=top_5_data, is_json=True)['answer']\n",
    "    code_to_run = json.loads(result)[\"code_to_run\"] if isinstance(result,str) else result[\"code_to_run\"]\n",
    "    execution = sbx.run_code(code_to_run)\n",
    "    print(execution)\n",
    "    img_bytes = base64.b64decode(execution.results[0].text)\n",
    "    img_url=upload_png_to_s3(get_s3_client(), 'charts',img_bytes)\n",
    "    chart_data.append( {'title' : _['Title'], 'description' : _['Description'], 'chart_url': img_url } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('local/chart_output.json', 'w') as f:\n",
    "    f.write(json.dumps(chart_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {col: str(df[col].dtype) for col in df.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_run = \"\"\"\n",
    "import subprocess\n",
    "\n",
    "# Ensure Kaleido is installed\n",
    "subprocess.run([\"pip\", \"install\", \"kaleido\"], check=True)\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import io\n",
    "import base64\n",
    "\n",
    "df = pd.read_csv('/home/user/sandbox/data.csv')\n",
    "#NEVER CHANGE THE ABOVE LINES OF CODE, UNLESS EXTRA LIBRARIES ARE REQUIRED FOR INPORT\n",
    "\n",
    "# Convert DATA_DATE to datetime format\n",
    "df['DATA_DATE'] = pd.to_datetime(df['DATA_DATE'])\n",
    "\n",
    "# Create the plot\n",
    "fig = px.line(df, x='DATA_DATE', y='MOVING_AVERAGE_30', title='S&P 500 30-Day Moving Average')\n",
    "\n",
    "#NEVER CHANGE THE BELOW LINES OF CODE\n",
    "img_bytes = io.BytesIO()\n",
    "fig.write_image(img_bytes, format=\"png\")  # Requires kaleido\n",
    "img_base64 = base64.b64encode(img_bytes.getvalue()).decode(\"utf-8\")\n",
    "img_base64\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sandbox.core import python_sandbox\n",
    "with open('local/charts.json', 'r') as f:\n",
    "    chart_metadata = json.loads(f.read())\n",
    "chart_data = python_sandbox(chart_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 19:55:37,592 - =====ENTRY POINT=====\n",
      "2025-03-31 19:55:37,618 - =====CHART TOOL=====\n",
      "2025-03-31 19:55:37,640 - =====PREPROCESSING STARTED=====\n",
      "\u001b[92m19:55:37 - LiteLLM:INFO\u001b[0m: utils.py:3056 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "2025-03-31 19:55:37,658 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "2025-03-31 19:55:37,666 - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.13.1, Platform: Windows-11-10.0.22631-SP0\n",
      "2025-03-31 19:55:37,672 - Connecting to GLOBAL Snowflake domain\n",
      "2025-03-31 19:55:37,674 - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2025-03-31 19:55:39,401 - Request POST https://api.e2b.app/sandboxes\n",
      "2025-03-31 19:55:40,066 - HTTP Request: POST https://api.e2b.app/sandboxes \"HTTP/1.1 201 Created\"\n",
      "2025-03-31 19:55:40,067 - Response 201\n",
      "2025-03-31 19:55:40,728 - Request: POST https://49983-irk5wjhv8o4li9d94la85-07168b26.e2b.app/files\n",
      "2025-03-31 19:55:41,121 - Response: 200 https://49983-irk5wjhv8o4li9d94la85-07168b26.e2b.app/files\n",
      "2025-03-31 19:55:41,122 - HTTP Request: POST https://49983-irk5wjhv8o4li9d94la85-07168b26.e2b.app/files?username=user&path=%2Fhome%2Fuser%2Fsandbox%2Fdata.csv \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m19:55:41 - LiteLLM:INFO\u001b[0m: utils.py:3056 - \n",
      "LiteLLM completion() model= gemini-2.5-pro-exp-03-25; provider = gemini\n",
      "2025-03-31 19:55:41,124 - \n",
      "LiteLLM completion() model= gemini-2.5-pro-exp-03-25; provider = gemini\n",
      "2025-03-31 19:55:48,127 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-exp-03-25:generateContent?key=AIzaSyB03UDAJTn8_d2zyWS_fsqhix9zSytutDY \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m19:55:48 - LiteLLM:INFO\u001b[0m: utils.py:1165 - Wrapper: Completed Call, calling success_handler\n",
      "2025-03-31 19:55:48,130 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m19:55:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "2025-03-31 19:55:48,133 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "\u001b[92m19:55:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "2025-03-31 19:55:48,135 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "2025-03-31 19:55:48,150 - Request: POST https://49999-irk5wjhv8o4li9d94la85-07168b26.e2b.app/execute\n",
      "\u001b[92m19:55:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "2025-03-31 19:55:48,156 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "2025-03-31 19:55:48,435 - Response: 200 https://49999-irk5wjhv8o4li9d94la85-07168b26.e2b.app/execute\n",
      "2025-03-31 19:55:48,436 - HTTP Request: POST https://49999-irk5wjhv8o4li9d94la85-07168b26.e2b.app/execute \"HTTP/1.1 200 OK\"\n",
      "2025-03-31 19:55:56,658 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m19:55:56 - LiteLLM:INFO\u001b[0m: utils.py:1165 - Wrapper: Completed Call, calling success_handler\n",
      "2025-03-31 19:55:56,672 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m19:55:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "2025-03-31 19:55:56,673 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m19:55:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "2025-03-31 19:55:56,675 - =====PREPROCESSING ENDED=====\n",
      "2025-03-31 19:55:56,673 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "\u001b[92m19:55:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "2025-03-31 19:55:56,679 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "2025-03-31 19:56:01,029 - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.13.1, Platform: Windows-11-10.0.22631-SP0\n",
      "2025-03-31 19:56:01,031 - Connecting to GLOBAL Snowflake domain\n",
      "2025-03-31 19:56:01,032 - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2025-03-31 19:56:02,344 - Request POST https://api.e2b.app/sandboxes\n",
      "2025-03-31 19:56:02,670 - HTTP Request: POST https://api.e2b.app/sandboxes \"HTTP/1.1 201 Created\"\n",
      "2025-03-31 19:56:02,671 - Response 201\n",
      "2025-03-31 19:56:03,298 - Request: POST https://49983-i6yqsc8ocfkhuxuggl79y-a99f3d0b.e2b.app/files\n",
      "2025-03-31 19:56:03,909 - Response: 200 https://49983-i6yqsc8ocfkhuxuggl79y-a99f3d0b.e2b.app/files\n",
      "2025-03-31 19:56:03,910 - HTTP Request: POST https://49983-i6yqsc8ocfkhuxuggl79y-a99f3d0b.e2b.app/files?username=user&path=%2Fhome%2Fuser%2Fsandbox%2Fdata.csv \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m19:56:03 - LiteLLM:INFO\u001b[0m: utils.py:3056 - \n",
      "LiteLLM completion() model= gemini-2.5-pro-exp-03-25; provider = gemini\n",
      "2025-03-31 19:56:03,912 - \n",
      "LiteLLM completion() model= gemini-2.5-pro-exp-03-25; provider = gemini\n",
      "2025-03-31 19:56:13,171 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-exp-03-25:generateContent?key=AIzaSyB03UDAJTn8_d2zyWS_fsqhix9zSytutDY \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m19:56:13 - LiteLLM:INFO\u001b[0m: utils.py:1165 - Wrapper: Completed Call, calling success_handler\n",
      "2025-03-31 19:56:13,173 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m19:56:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "2025-03-31 19:56:13,175 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "\u001b[92m19:56:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "2025-03-31 19:56:13,177 - Request: POST https://49999-i6yqsc8ocfkhuxuggl79y-a99f3d0b.e2b.app/execute\n",
      "2025-03-31 19:56:13,175 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "\u001b[92m19:56:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "2025-03-31 19:56:13,179 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "2025-03-31 19:56:13,587 - Response: 200 https://49999-i6yqsc8ocfkhuxuggl79y-a99f3d0b.e2b.app/execute\n",
      "2025-03-31 19:56:13,588 - HTTP Request: POST https://49999-i6yqsc8ocfkhuxuggl79y-a99f3d0b.e2b.app/execute \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from utils.langgraph.core import entry_point\n",
    "import json\n",
    "with open('links.json', 'r', encoding='utf-8') as file:\n",
    "    links_data = json.load(file)\n",
    "llm_ready_data = entry_point(links_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:42:38 - LiteLLM:INFO\u001b[0m: utils.py:3056 - \n",
      "LiteLLM completion() model= gemini-2.5-pro-exp-03-25; provider = gemini\n",
      "2025-03-31 19:42:38,005 - \n",
      "LiteLLM completion() model= gemini-2.5-pro-exp-03-25; provider = gemini\n",
      "2025-03-31 19:44:33,132 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-exp-03-25:generateContent?key=AIzaSyB03UDAJTn8_d2zyWS_fsqhix9zSytutDY \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m19:44:33 - LiteLLM:INFO\u001b[0m: utils.py:1165 - Wrapper: Completed Call, calling success_handler\n",
      "2025-03-31 19:44:33,163 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m19:44:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "2025-03-31 19:44:33,164 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "2025-03-31 19:44:33,165 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "\u001b[92m19:44:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n",
      "2025-03-31 19:44:33,181 - selected model name for cost calculation: gemini/gemini-2.5-pro-exp-03-25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://sfopenaccessbucket.s3.us-east-1.amazonaws.com/report/static.md'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.langgraph.core import generate_report_without_streaming\n",
    "from utils.s3.core import get_s3_client, write_markdown_to_s3\n",
    "markdown_string =  generate_report_without_streaming(llm_ready_data)\n",
    "write_markdown_to_s3(get_s3_client(), markdown_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
